<!DOCTYPE html>
<html dir="ltr" lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AoN Brainhack Warsaw 2017</title>
  <meta name="keywords" content="brainhack, hackaton, neuroscience, warsaw, cognitive science, fMRI, modelling, simulations, open science">
  <meta name="description" content="Bring your ideas on open, reproducible neuroscience related projects to AoN Brainhack Warsaw 2017! The call for proposals for is now open! Brainhack Warsaw is an official satellite event for Aspects of Neuroscience conference.">
  <!-- social media -->
  <meta property="og:title" content="AoN Brainhack Warsaw 2017" />
  <meta property="og:type" content="website" />
  <meta property="og:url" content="http://0.0.0.0:4000" />
  <meta property="og:image" content="http://0.0.0.0:4000/img/banner-fb.png" />
  <meta property="og:site_name" content="AoN Brainhack Warsaw 2017" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@" />	
  <meta name="twitter:creator" content="@" />
  <meta name="twitter:title" content="AoN Brainhack Warsaw 2017" />
  <meta name="twitter:description" content="The call for proposals for the AoN Brainhack Warsaw 2017 is now open!" />
  <meta name="twitter:image:src" content="http://0.0.0.0:4000/img/banner-fb.png">
  <!-- style -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.97.0/css/materialize.min.css">
  <link rel="stylesheet" href="stylesheets/combo.css">
  <link rel="stylesheet" href="stylesheets/style.css">
  <link href='https://fonts.googleapis.com/css?family=Raleway:400,300,700' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/jquery.slick/1.5.7/slick.css">
  <link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/jquery.slick/1.5.8/slick-theme.css"/>
  <link rel="stylesheet" href="stylesheets/css/overrides.css">
  <!-- icons -->
  <link rel="shortcut icon" type="image/png" href="http://0.0.0.0:4000/img/favicon.png?">
  
<script>
 (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
 (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
 m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
 })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

 ga('create', 'UA-104097157-1', 'auto');
 ga('send', 'pageview');

</script>



</head>
<body>
  <div id="main">

    <nav>
      <a href="#" data-activates="mobile-demo" class="button-collapse"><i class="right fa fa-bars"></i></a>
      <ul class="hide-on-med-and-down">
      
        
        <li class="p-intro"><a href="#intro">intro</a></li>
      
        
        <li class="p-about"><a href="#about">About</a></li>
      
        
        <li class="p-venue"><a href="#venue">Venue</a></li>
      
        
        <li class="p-speakers"><a href="#speakers">Speakers</a></li>
      
        
        <li class="p-projects"><a href="#projects">Projects</a></li>
      
        
        <li class="p-schedule"><a href="#schedule">schedule</a></li>
      
        
        <li class="p-register"><a href="#register">Registration</a></li>
      
        
        <li class="p-comitee"><a href="#comitee">committee</a></li>
      
      </ul>
      <ul class="side-nav" id="mobile-demo">
      
        
        <li class="p-intro"><a href="#intro">intro</a></li>
      
        
        <li class="p-about"><a href="#about">About</a></li>
      
        
        <li class="p-venue"><a href="#venue">Venue</a></li>
      
        
        <li class="p-speakers"><a href="#speakers">Speakers</a></li>
      
        
        <li class="p-projects"><a href="#projects">Projects</a></li>
      
        
        <li class="p-schedule"><a href="#schedule">schedule</a></li>
      
        
        <li class="p-register"><a href="#register">Registration</a></li>
      
        
        <li class="p-comitee"><a href="#comitee">committee</a></li>
      
      </ul>
    </nav>


    
      
      <div id="intro" class="section p-intro">
        
        <div class="container center">
          <p><img src="img/aon-logo.png" alt="codeweek" /></p>

<h2>Aspects of Neuroscience conference satellite  event</h2>

<h3>17-19th November 2017 @  University of Warsaw</h3>


        </div>
      </div>
    
      
      <div id="about" class="section p-about">
        
        <div class="container ">
          <h1>The call for proposals for the AoN Brainhack Warsaw 2017 is now open!</h1>

<p>On the weekend of <strong>17-19th November 2017</strong>, the first edition of <strong>AoN Brainhack Warsaw</strong> will take place. During this two-day event dedicated to students and PhD students, we will work in teams on <strong>neuroscience-related projects</strong>.</p>

<p>The aim of the event is to meet new, enthusiastic researchers, make new friendships in academia, learn, share the knowledge on data mining and brain research, but also promote open science in the spirit of the whole Brainhack community <a href="https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0121-x">(Craddock et al., 2016)</a>. Attendees  of various backgrounds are welcome to join!</p>

<p>By submitting your own, genuine research project, you can gain a priceless leadership experience as you will manage a group of researchers at our two-day event.</p>

<p>Please note AoN Brainhack Warsaw 2017 is a satellite event for the interdisciplinary  <a href="http://neuroaspects.org/">Aspects of Neuroscience conference</a>  which will take place on 24-26th November 2017 in Warsaw. 
Participation in the conference is not mandatory to take part in Brainhack but we encourage to also consider this.</p>

<p><strong>Deadline for project proposals</strong>:                     01.09.2017</p>

<p><strong>Announcement of projects</strong>:                           15.09.2017</p>

<p><strong>Deadline for participant registration</strong>:               01.11.2017</p>

<p>Please send the project proposals and all the related questions at the mailing address: <a href="mailto:brainhackwarsaw@gmail.com">brainhackwarsaw@gmail.com</a></p>

<p>Also, please team up with us! Join our channel (#brainhack-warsaw-2017) on <a href="https://brainhack-slack-invite.herokuapp.com/">Brainhack Slack</a> for updated information on the developing Hackathon content and to contribute your own ideas.</p>


        </div>
      </div>
    
      
      <div id="venue" class="section p-venue">
        
        <div class="container ">
          <h1>Venue</h1>

<p>Brainhack will take place at the  <strong>University of Warsaw, Faculty of Physics, Pasteura 5, 02-093 Warsaw, Poland</strong>. Additional information how to get to Warsaw and university campus  can be found at the <a href="http://neuroaspects.org/getting-to-warsaw-and-faculty-of-biology">AoN website</a>.</p>

<div class="icontain">
  <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2444.7040269753106!2d20.98086791549002!3d52.21242587975718!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x471eccece2d062d9%3A0xeb502e63f53718c9!2sWydzia%C5%82+Fizyki+Uniwersytetu+Warszawskiego!5e0!3m2!1spl!2spl!4v1501617472587" allowfullscreen=""></iframe>
</div>


        </div>
      </div>
    
      
      <div id="speakers" class="section p-speakers">
        
        <div class="container ">
          <h1>Speakers</h1>

<p><a name="hanke"></a></p>

<aside class="speaker-card ">
   <header>
    <h3></h3>
<a href="http://psychoinformatics.de/">
   <img src="http://0.0.0.0:4000/img/speakers/michael.jpg" /></a>
<h4>Michael Hanke, PhD 




 

</h4>


  <h6>Psychoinformatics Lab, Institut für Psychologie, Otto-von-Guericke-Universität,<br /> Magdeburg, Germany</h6>


   </header>
</aside>

<h4>Doing open science for your own benefit</h4>
<p><strong>Abstract:</strong> Everyday cognition involves a large variety of concurrent neural processes that handle an incredible amount of sensory inputs in order to generate appropriate responses when interacting with the environment. It can be argued that studying any of these aspects of cognition in isolation, as it is often the case in feature-deprived laboratory experiments, yields an over-simplified or over-specialized understanding of the true nature of brain function. In order to fully understand “how the brain works”, it is essential to study the complex inter-play of cognitive processes in a rich natural environment and go beyond the
localization of individual aspects of brain function. I will outline a strategy to approach this herculean task that is based on the core principles of open-science and aims to enable collaboration between research groups and disciplines.</p>

<p><strong>Bio:</strong>
Michael obtained his PhD in 2009 from Institute of Psychology, Otto-von-Guericke-University in Magdeburg, Germany. Today, he has a Junior professor position at his Alma Mater. Dr Hanke is an expert in sensory processing in vision and other modalities, and in sensory representations in the cortex. He is also actively promoting the ideas of open and reproducible science, and was one of the founders of the Brainhack organization which we represent at the AoN Brainhack Warsaw.</p>

<p><a name="kirstie"></a></p>
<aside class="speaker-card ">
   <header>
    <h3></h3>
<a href="https://whitakerlab.github.io">
   <img src="http://0.0.0.0:4000/img/speakers/kirstie.png" /></a>
<h4>Kirstie Whitaker, PhD 




 

</h4>


  <h6>Brain Mapping Unit, Department of Psychiatry, University of Cambridge</h6>


   </header>
</aside>

<h4>Shooting for the stars: Moving from reproducible to open research</h4>
<p><strong>Abstract:</strong>
This talk will discuss the perceived and actual barriers experienced by researchers attempting to do reproducible research in neuroscience, and give practical guidance on how they can be overcome. It will include suggestions on how to make your code and data available and usable for others (including a strong suggestion to document both clearly so you don’t have to reply to lots of email questions from future users). However, as this is a Brainhack event, Dr Whitaker will push you further: to consider working openly. Open research is an important step in changing an academic reward system from its current focus on individual contributions and “getting there first” to sharing work as it is being created and allowing collaborators to contribute from the start. All the AoN Brainhack Warsaw participants will leave knowing there is something they can do to step towards making their research reproducible, and hopefully a few will be inspired to make more radical changes.</p>

<p><strong>Bio:</strong>
Kirstie is a Research Fellow at The Alan Turing Institute (London, UK). She completed her PhD in Neuroscience at the University of California, Berkeley in 2012 and holds a BSc in Physics from the University of Bristol and an MSc in Medical Physics from the University of British Columbia. She was a postdoctoral researcher in the Department of Psychiatry at the University of Cambridge from 2012 to 2017. Dr Whitaker uses magnetic resonance imaging to study child and adolescent brain development and is a passionate advocate for reproducible neuroscience. She is a Fulbright scholarship alumna and 2016/17 Mozilla Fellow for Science. Kirstie was named, with her collaborator Petra Vertes, as a 2016 Global Thinker by Foreign Policy magazine.</p>

<p><a name="charl"></a></p>
<aside class="speaker-card ">
   <header>
    <h3></h3>
<a href="">
   <img src="http://0.0.0.0:4000/img/speakers/charl.png" /></a>
<h4> Charl Linssen, PhD candidate 




 

</h4>


  <h6>The Tiesinga group, Department of Neuroinformatics,<br /> Donders Institute for Brain, Cognition and Behaviour,<br /> Nijmegen, the Netherlands</h6>


   </header>
</aside>

<h4>Convergence between artificial intelligence and simulation of the brain: from theory to GitHub</h4>
<p><strong>Abstract:</strong> Artificial neural networks have received a recent spur in attention after notable successes in diverse areas: computer vision, motor control, natural language processing, as agents in computer and board games, and many others. Computer simulation of neural networks has been around since the late 1950s, but recent successes rely both on better knowledge of how to design and train these networks, as well as increases in scale made possible by increased computational power and the availability of large training datasets (“big data”).</p>

<p>For a neuroscientist, neural network simulation can be of interest from two different points of view: in the theoretical sense, as a model of how real brains work, or in the empirical sense, as a tool that analyses a dataset or performs a certain task (as in the game playing agent). These objectives may not be mutually exclusive, but depending on the application or goal, a researcher has to make concrete decisions about what model to use to approach it.</p>

<p>In this talk, we will review modern neural network architectures and consider them from the perspective of both theory and application. For example, if a certain network model requires a certain training paradigm, this could, on the application side, inform the allocation of CPU time, while on the theoretical side, lead to empirical predictions on neuronal biophysics involved in plasticity. Taken together, the goal is to give the audience (that’s you!) the knowledge needed to critically assess neural network models, and subsequently to download and run the chosen network on your own dataset and with your own selection of parameters.</p>

<p><strong>Bio:</strong>
Charl has a background in engineering, and is particularly interested in systems that actively respond to their environment. After studying Embedded Systems at TU Eindhoven, he realised that brains, or even something as comparatively simple as the nervous system of an insect, are ultimate embedded systems. Following this, he went on to pursue a Master’s program in Cognitive Neuroscience at Radboud University, where he is currently pursuing a PhD on the topic of active sensing in the rodent whisker system.  </p>


        </div>
      </div>
    
      
      <div id="projects" class="section p-projects">
        
        <div class="container ">
          <h1>Projects</h1>

<p>At the moment, <strong>the call for project proposals is closed</strong>. The proposals can include various forms of a group activity, e.g., data analysis, app development, a discussion club on a particular topic, developing a software etc. The organizers will provide a few openly available datasets to the project authors, but developing projects using private datasets is also welcome.</p>

<p><strong>A project proposal should contain the following points:</strong></p>
<ol>
  <li>a title,</li>
  <li>a list of authors / mentors / supervisors,</li>
  <li>an abstract,</li>
  <li>a list of 1-5 key papers / online materials summarising the subject (which the participants should become familiar with before starting the project),</li>
  <li>a list of requirements for taking part in the project (education level / English level / programming language required),</li>
  <li>a maximal number of participants on the project,</li>
  <li>what participants gain / learn from the project?,</li>
  <li>can the project be extended to a peer-reviewed paper if the results are promising?</li>
</ol>

<p>Two exemplary projects which will take place at this event, are listed below:</p>

<hr />

<h2><a id="connectivity"></a> Project 1: Functional connectivity research: can we find a common ground?</h2>

<h4>Authors: Natalia Bielczyk, Msc<sup>1</sup> <a href="mailto:natalia.bielczyk@gmail.com"><i class="fa fa-envelope"></i></a>  / Michał Bola, Phd <sup>2</sup></h4>

<ol>
  <li>Radboud University Nijmegen Medical Centre, Nijmegen, the Netharlands</li>
  <li>Nencki Institute of Experimental Biology, Warsaw, Poland</li>
</ol>

<p><strong>Abstract:</strong> 
Functional connectivity (FC) research has become one of the leading concepts used for characterising network dynamics across multiple disciplines, from neuroimaging, through gene expression networks, to social networks. It is also a basis for graph theoretical biomarkers of psychiatric disorders and as such, it become an important subfield of cognitive neuroimaging.</p>

<p>FC is usually operationalised by means of Pearson’s and partial correlation, however the implementation of FC can vary between different fields, and different applications. Then, there is a question: does an optimal method to quantify functional connectivity exist? Or is the choice dependent on the data properties? How to choose the right method? In this project, we will use open-access data from functional Magnetic Resonance Imaging, EEG, gene expression data, stock exchange data and a few other open-access datasets, and we will compare the leading methods for computing FC when applied to these datasets.</p>

<p>We will attempt to answer the questions: what are the pros and cons of different methods for quantifying FC? What are the differences and the similarities between different datasets, and how to choose the right method for the given dataset?</p>

<p><img src="http://0.0.0.0:4000/img/projects/project1.png?style=centerme" alt="test image size" class="img-responsive" height="80%" width="80%" align="center" /></p>

<p><em>Fig: different types of networks. A: a social network (Facebook); B: correlations on the stock exchange (106 companies listed at NASDAQ-100); C: a gene co-expression network (image adapted from http://wikipedia.org on CC BY-SA 3.0 license); D: large scale resting state networks in the brain (image adapted from Smith et al, 2009)</em></p>

<p><strong>A list of 1-5 key papers/materials summarising the subject</strong>:</p>
<ol>
  <li><a href="http://www.scholarpedia.org/article/Brain_connectivity">http://www.scholarpedia.org/article/Brain_connectivity</a></li>
  <li><a href="http://journal.frontiersin.org/article/10.3389/fnsys.2015.00175/full">http://journal.frontiersin.org/article/10.3389/fnsys.2015.00175/full</a></li>
  <li>A. K. Enge, C. Gerloff,C. C. Hilgetag and G. Nolte (2013). Intrinsic Coupling Modes: Multiscale Interactions in Ongoing Brain Activity. Neuron 80 (4): 867–86</li>
  <li>M. Bola and V. Borchardt (2016). Cognitive Processing Involves Dynamic Reorganization of the Whole-Brain Network’s Functional Community Structure. Journal of Neuroscience 36 (13): 3633–5</li>
</ol>

<p><strong>A list of requirements for taking part in the project:</strong></p>
<ul>
  <li>BSc program, or higher</li>
  <li>English: good, not necessarily proficient</li>
  <li>programming languages / other competences: basics of Matlab, Python, LaTeX, basic statistics</li>
</ul>

<p><strong>A maximal number of participants</strong>: 10 (will be working in pairs)</p>

<p><strong>Skills and competences you can learn during the project</strong>:</p>

<ol>
  <li>looking for parallels in the datasets from different disciplines, representing the datasets with a model</li>
  <li>group project planning (we will discuss and divide tasks on the site)</li>
  <li>programming in a team, solving problems in parallel</li>
  <li>scientific writing (at least one paragraph per participant)</li>
</ol>

<p><strong>Is there a plan for extending this work to a paper in case the results are promising?</strong> Yes</p>

<hr />
<p><a id="trypophobia"></a></p>
<h2>Project 2: Detecting trypophobia triggers</h2>

<h4>Author: Piotr Migdał, PhD<sup>1</sup> <a href="mailto:pmigdal@gmail.com"><i class="fa fa-envelope"></i></a></h4>

<ol>
  <li>deepsense.io</li>
</ol>

<p><strong>Abstract</strong>:Trypophobia is a phobia of irregular patterns or clusters of small holes or bumps. It may arise from the sense of aversion towards skin infection with maggots or fungi. In general, this phenomenon is adaptive, because a strong sense of disgust may protect against touching infected humans, animals or corpses. Yet, it can also become maladaptive if some, otherwise benign, patterns cause a strong aversive response. During this workshop we will create an artificial convolutional neural network that predicts if an image is likely to cause a trypophobic response. Such networks are a state of the art technique for visual pattern detection.</p>

<p>The goal of the project is twofold:</p>

<ol>
  <li>provide a tool to filter or censor triggering images while browsing the Internet</li>
  <li>empirically explore which patterns contribute to this phenomenon, and potentially relate the results to analogous regions in the human visual cortex</li>
</ol>

<p>We will provide the data for this project. The initial results are promising, see <a href="https://github.com/grzegorz225/trypophobia-detector">this git repo</a>.</p>

<p><img src="http://0.0.0.0:4000/img/projects/project2.png?style=centerme" alt="image-title-here" class="img-responsive" height="80%" width="80%" align="center" />
<em>Fig: The holes in lotus seed heads cause some anxiety in some people (source: Wikipedia)</em></p>

<p><strong>A list of 1-5 key papers/materials summarising the subject</strong>:</p>

<p>In this case, only the basic knowledge of trypophobia is required. An additional knowledge may help with giving a general context, but most likely won’t contribute to the solution during this event:</p>
<ol>
  <li><a href="https://en.wikipedia.org/wiki/Trypophobia">https://en.wikipedia.org/wiki/Trypophobia</a></li>
  <li><a href="https://www.reddit.com/r/trypophobia/">https://www.reddit.com/r/trypophobia/</a> (warning: triggers)</li>
</ol>

<p>Additionally, take a look at <a href="http://p.migdal.pl/2017/04/30/teaching-deep-learning.html">http://p.migdal.pl/2017/04/30/teaching-deep-learning.html</a>.
If you are new to Python, this <a href="http://www.southampton.ac.uk/~fangohr/teaching/python/book.html">book</a>  may be relevant.</p>

<p><strong>A list of requirements for taking part in the project</strong>:</p>
<ul>
  <li>BSc program, or higher</li>
  <li>English: good, not necessarily proficient</li>
  <li>programming languages / other competences: at least basics of Python (we will create a neural network in either Keras or PyTorch, modern frameworks for deep learning)</li>
</ul>

<p><strong>A maximal number of participants</strong>: 6 (1-2 per computer)</p>

<p><strong>Skills and competences you can learn during the project</strong>:</p>
<ol>
  <li>practical experience with deep learning for image classification</li>
  <li>insights into how artificial neural networks abstract visual information processing</li>
</ol>

<p><strong>Is there a plan for extending this work to a paper in case the results are promising?</strong> Yes</p>

<hr />
<p><a id="game"></a></p>
<h2>Project 3: Development of video game for studying joint action dynamics</h2>

<h4>Authors: Julian Zubek, PhD <a href="mailto:zubekj@gmail.com"><i class="fa fa-envelope"></i></a> / Arkadiusz Białek, PhD</h4>

<p><strong>Abstract:</strong>
The goal of the project is to create a playable video game for two players, which will be applied in a psychological experiment to measure capabilities for “joint action”—non accidental, coordinated behaviour of two or more individuals aimed at achieving their common goal.</p>

<p>A great many processes of different levels of complexity can be described in terms of joint action, from simple tasks such as carrying a heavy object together to playing a piano duet or engaging in linguistic exchange (Sebanz et al. 2006). Joint action tasks may be characterized by role distribution: there may be parallel roles (highly similar) or complementary roles (different, but interdependent) (Warneken et al. 2006). It is suggested that joint action processes are crucial to our development and survival as social species (Tomasello 2014). Identifying and understanding qualities of behavioural coordination and cognitive mechanisms governing joint action is an ongoing research endeavour. One promising approach is to construct an experimental task in the form of video game (Satta et al. 2017). This allows defining cooperation goals in the context of an artificial environment in which all aspects of environmental dynamics can be controlled. We can register specific actions performed by the players—such as cursor movements—and analyse them as interrelated time series in terms of synchronicity, recurrence, leader-follower relations etc. Such dynamical measures, when compared with other behavioural and psychological characteristics of the participants, may provide us deeper insights as to the factors determining quality of joint action.</p>

<p>Our game will be developed from scratch during the 2-day Brianhack, using ideas from participants. We will work on all aspects of game design: the concept, the graphics, programming, etc (while taking into account time constraints).</p>

<p><img src="http://0.0.0.0:4000/img/projects/project3_1.png" alt="image-title-here" class="img-responsive" height="50%" width="50%" /><img src="http://0.0.0.0:4000/img/projects/project3_b.png" alt="image-title-here" class="img-responsive" height="100%" width="50%" /></p>

<p><strong>The general requirements for the game are as follows:</strong></p>

<ul>
  <li>Game developed in Python+Kivy, multiple platform support</li>
  <li>Real time gameplay for two players</li>
  <li>Support for control using touchscreen</li>
  <li>Cooperative game in which both players try to achieve a common goal</li>
  <li>Game accessible to 6-7 year old children and their parents</li>
  <li>Possibility to measure different facets of joint action, i.e. containing parallel and complementary roles</li>
  <li>Optionally (only for parallel roles part of the game): single player mode (as control condition)</li>
</ul>

<p>While working on this project, we will gather insights into collaborative processes from two different perspectives: the perspective of a researcher planning an experiment, and the perspective of a group member engaged in collaborative task. Hopefully, this will be an enjoyable and stimulating experience.</p>

<p>General agenda:</p>
<ul>
  <li>Day 0: Getting to know each other.</li>
  <li>Day 1: Introduction and inspiration. Brainstorming session. Game outline. Introduction to game programming in Kivy. Useful design patterns.</li>
  <li>Day 2: Implementing the game. Preparing graphics. Testing. Wrap up.</li>
</ul>

<p><strong>A list of 1-5 key papers/materials summarising the subject:</strong></p>
<ol>
  <li>Satta, E., Ferrari-Toniolo, S., Visco-Comandini, F., Caminiti, R., &amp; Battaglia-Mayer, A. (2017). Development of motor coordination during joint action in mid-childhood. Neuropsychologia. https://doi.org/10.1016/j.neuropsychologia.2017.04.027</li>
  <li>Sebanz, N., Bekkering, H., &amp; Knoblich, G. (2006). Joint action: bodies and minds moving together. Trends in Cognitive Sciences, 10(2), 70–76. https://doi.org/10.1016/j.tics.2005.12.009</li>
  <li>Tomasello, M. (2014). The ultra-social animal. European Journal of Social Psychology, 44(3), 187–194. https://doi.org/10.1002/ejsp.2015</li>
  <li>Warneken, F., Chen, F., &amp; Tomasello, M. (2006). Cooperative activities in young children and chimpanzees. Child Development, 77(3), 640–663. https://doi.org/10.1111/j.1467-8624.2006.00895.x</li>
</ol>

<p><strong>A list of requirements for taking part in the project:</strong></p>
<ul>
  <li>BSc program, or higher</li>
  <li>Communicative English</li>
  <li>Some experience in Python programming and/or computer graphics and/or game design</li>
</ul>

<p><strong>A maximal number of participants:</strong>6</p>

<p><strong>Skills and competences to be acquired during the project:</strong></p>
<ul>
  <li>Experimental design</li>
  <li>Creative design</li>
  <li>Basics of game programming in Python</li>
  <li>Good programming practices (test-driven development, pair programming, code review)</li>
</ul>

<p><strong>Is there a plan for extending this work to a paper in case the results are promising?</strong>
The developed game will be released as open source software. It will be used as one of the experimental tasks in an ongoing research project. Interested participants may be invited to further collaboration.</p>

<hr />

<h2>Project 4: Training a human-like movie evaluation system based on the semantic features of the storylines</h2>

<h4>Authors: Julia Immiora <a href="mailto:ju.berezutskaya@gmail.com"><i class="fa fa-envelope"></i></a>  / Marcel van Gerven</h4>

<p><strong>Abstract:</strong>
One of the interesting questions in behavioral neuroscience is how humans evaluate perceived complex information. For example, we would like to understand what makes a movie to be rated high or low on average. Specifically, it is interesting to see whether the information about the movie, such as the movie description, its cast, genre and other attributes, is predictive of the average rating the movie receives.</p>

<p>In our project, we want to develop a model that predicts IMDb ratings of the movies based on their descriptions. To our knowledge, the existing algorithms attempt to predict IMDb ratings based on meta-information about the movies: directors, actors, genre, year, movie length and so on (Hsu et al., 2014; San, 2016). We believe that one of the key indicators of the movie reception is the movie storyline along with its character descriptions. In the present project, we aim at building a model that predicts IMDb ratings using movie storyline information.</p>

<p>We propose to start with a baseline classifier, such as a random forest classifier, which takes in the key content words from the movie storyline description and predicts the IMDb rating of the movie. The performance of this model should tell us whether the simple ‘bag of words’ representation of the movie storyline can be predictive of the movie rating.</p>

<p>The second approach will entail training a discriminative deep neural network, which will take in the full storyline descriptions preserving the temporal relationships between the words, and predict the IMDb rating of the movie. The difference in model performance compared to the decision tree classifier should tell us whether the temporal dependences in the storyline description provide additional information about how the movie is going to be rated. It will also be interesting to see whether we will be able to retrieve more high-level semantic features from the text input, such as elements of the plot.</p>

<p>In both cases, we can make use of pretrained word embeddings to represent text information, such as word2vec (Mikolov et al., 2013) or GloVe (Pennington et al., 2014). In addition, IMDb movie tags, capturing various meta-information about the movies (e.g. genre, year of production and so on) can be included as additional predictors in both models.</p>

<p>We believe that in case of success this project can provide information about the trends in human behavior when it comes to evaluation of the movie input. It will be interesting to see whether we will be able to uncover the semantic features that influence the movie reception by public.</p>

<p><img src="http://0.0.0.0:4000/img/projects/project4.png?style=centerme" alt="image-title-here" class="img-responsive" height="80%" width="80%" align="center" /></p>

<p><strong>A list of 1-5 key papers/materials summarising the subject:</strong></p>
<ol>
  <li>Hsu, P.-Y., Shen, Y.-H., and Xie, X.-A. (2014). Predicting Movies User Ratings with Imdb Attributes. In International Conference on Rough Sets and Knowledge Technology, (Springer), pp. 444–453.</li>
  <li>Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013). Efficient estimation of word representations in vector space. ArXiv Prepr. ArXiv13013781.</li>
  <li>Pennington, J., Socher, R., and Manning, C.D. (2014). Glove: Global vectors for word representation. In EMNLP, pp. 1532–1543.</li>
  <li>San, C. (2016). Predict Movie Ratings: https://github.com/sundeepblue/movie_rating_prediction</li>
</ol>

<p><strong>A list of requirements for taking part in the project:</strong></p>
<ul>
  <li>BSc program, or higher</li>
  <li>English: good, not necessarily proficient</li>
  <li>good Python programming skills and basic familiarity with machine learning and deep learning</li>
  <li>familiarity with Tensorflow, PyTorch or ChainerA maximal number of participants:</li>
</ul>

<p><strong>A maximal number of participants:</strong> 5</p>

<p><strong>Is there a plan for extending this work to a paper in case the results are promising?</strong> yes</p>

<hr />
<h2>Project 5: Hypothesis­-driven white matter tractography from T1­-weighted MRI images</h2>

<h4>Authors: Anastasia Osoianu / Charl Linssen <a href="mailto:charl@turingbirds.com"><i class="fa fa-envelope"></i></a> / Katja Heuer / Roberto Toro</h4>

<p><strong>Abstract:</strong>
Polarized light imaging (PLI) as well as the tractography of high angular resolution diffusion weighted imaging (DWI) data reveal a gross white matter (WM) geometry of striking regularity[<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>,<sup id="fnref:3"><a href="#fn:3" class="footnote">2</a></sup>]. This makes the neuroanatomist wonder whether it would be possible to generate a connectome based exclusively on a small set of hypotheses:</p>

<ul>
  <li>more than 90% of white matter connections are cortico­cortical</li>
  <li> the density of fibres is homogeneous throughout the white matter</li>
  <li>fibres are oriented perpendicular to gyral crowns and parallel to sulcal fundi</li>
  <li>fibres are sticky, which makes them aggregate in bundles of similar orientation.
How much of a real brain connectome would be recovered by such a simple and reductionistic model?</li>
</ul>

<p>We propose to approach this question in the simple case of a 2D coronal slice. We use methods inspired by swarm intelligence[<sup id="fnref:2"><a href="#fn:2" class="footnote">3</a></sup>], and simulate a dynamical system where particles are instantiated at the gray matter/white matter boundary. The particles are allowed to propagate within the white matter mask, following simple rules that reflect the above list of hypotheses. After reaching a steady state, the white matter orientation distribution is reconstructed on a voxel-by-voxel basis, for each individual voxel based on the statistics of the particle paths crossing it. This is roughly the opposite of streamline tractography, where paths are sampled based on a distribution map. By implementing derived measures such as an anisotropy index, the resulting map can be quantitatively compared to empirical data. We are especially interested in multimodal effects that occur e.g. when two fibre bundles cross. We will validate our model on coronal slices of the vervet monkey, as an excellent empirical dataset is available [<sup id="fnref:3:1"><a href="#fn:3" class="footnote">2</a></sup>]. Proof­ of­ concept code is available via GitHub[<sup id="fnref:4"><a href="#fn:4" class="footnote">4</a></sup>].</p>

<p><img src="http://0.0.0.0:4000/img/projects/project5.jpg?style=centerme" alt="image-title-here" class="img-responsive" height="80%" width="80%" align="center" /></p>

<p><strong>A list of 1-5 key papers/materials summarising the subject:</strong></p>
<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Frontier Research Topic “Wiring Principles of Cerebral Cortex” — http://journal.frontiersin.org/researchtopic/168/wiring-principles-of-cerebral-cortex#articles&nbsp;<a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p>Vervet monkey brain slice scanned using Polarized Light Imaging — http://microdraw.pasteur.fr/microdraw.html?source=/vervet/vervet.json&nbsp;<a href="#fnref:3" class="reversefootnote">&#8617;</a>&nbsp;<a href="#fnref:3:1" class="reversefootnote">&#8617;<sup>2</sup></a></p>
    </li>
    <li id="fn:2">
      <p>Craig Reynolds’ “Boids” — http://www.red3d.com/cwr/boids/&nbsp;<a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p> https://github.com/aniv0s/FakeTensorImaging&nbsp;<a href="#fnref:4" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

<p><strong>A list of requirements for taking part in the project:</strong></p>

<ul>
  <li>familiarity with Python, Javascript or similar programming language</li>
  <li>affinity for simulating and analysing dynamical systems</li>
</ul>

<p><strong>A maximal number of participants on the project:</strong> 6</p>

<p><strong>Skills and competences you can learn during the project:</strong>
You will reflect on the organisational principles of white matter network connectivity across spatial scales, and formulate hypotheses about it. The simulation will be used to test as well as generate these hypotheses. The outcome of the simulation is continuously compared to that derived from PLI images.</p>

<p>Next to collective brainstorming, you can focus on any of two main themes in the project:</p>
<ol>
  <li>metrics and quantification, e.g. downloading and processing the PLI images; design the anatomical WM mask; computing derived measures such as anisotropy indices; comparison (e.g. Kullbeck-Leibler divergence) with the map generated by the simulation;</li>
  <li>development of the simulation method: what rules do particles propagate under? parameter optimisation using smart search (particle swarm optimisation on the parameters? meta-metaheuristic!), generate appropriate network graph (e.g. having small-world properties) that goes into the particle simulation as a boundary condition</li>
</ol>

<p><strong>Is there a plan for extending this work to a paper in case the results are promising?</strong> Yes</p>

<hr />
<h2>Project 6: One channel EEG sleep staging with open source and open hardware NeuroOn sleep mask</h2>

<h4>Authors: Paweł Kazimieczak / Franciszek Rakowski <a href="mailto:james.cole@imperial.ac.uk"><i class="fa fa-envelope"></i></a></h4>

<p><strong>Abstract:</strong>
This project means data science and your brain in daily practice!
Participants will have an opportunity to carry out EEG signal registration with the NeuroOn-Open mask. The NeuroOn-Open mask is a simple and portable device equipped with 2 EEG electrodes, pulse-oximeter and blood oxygen saturation measurement device.</p>

<p>Our project will consist of three steps:</p>
<ul>
  <li>performing the experiment (registration), with a kind help of firmware authors and a medical doctor</li>
  <li>a dedicated lecture on signal processing</li>
  <li>a coding time</li>
</ul>

<p>The coding will involve:</p>
<ol>
  <li>performing signal quality check</li>
  <li>designing and implementing features of the short epochs of the signal</li>
  <li>choosing the appropriate machine learning algorithm, and carrying out classification of the sleep epochs as belonging to the light, deep and REM sleep stages.</li>
</ol>

<p>The reference staging will be given by additional sleep stager (Philips Alice) or medical doctor examination.</p>

<p><img src="http://0.0.0.0:4000/img/projects/project6_3.png" alt="image-title-here" class="img-responsive" height="50%" width="50%" /><img src="http://0.0.0.0:4000/img/projects/project6_2.png" alt="image-title-here" class="img-responsive" height="100%" width="50%" /></p>

<p><strong>A list of 1-5 key papers summarising the subject:</strong></p>

<ol>
  <li>Neuroon Open hardware documentation: https://github.com/inteliclinic/NeuroonOpenHardwareDocumentation/blob/master/Neurooon_Open
_Hardware_Documentation_rev0002.pdf</li>
  <li>Benjamin D. Yetton, Mohammad Niknazar, Katherine A. Duggan, Elizabeth A. McDevitt, Lauren N. Whitehurst, Negin Sattari, Sara C. Mednick Automatic detection of rapid eye movements (REMs): A machine learning approach. Journal of Neuroscience Methods, 259 (2016)</li>
  <li>A Comparative Study on Classification of Sleep Stage Based on EEG Signals Using Feature Selection and Classification AlgorithmsBaha Şen &amp; Musa Peker &amp; Abdullah Çavuşoğlu &amp; Fatih V. Çelebi J Med Syst (2014)</li>
  <li>Neuron-Open on Kickstarter: https://www.kickstarter.com/projects/intelclinic/neuroon-open- smartest-sleep-dreams-and-meditation</li>
</ol>

<p><strong>A list of requirements for taking part in the project:</strong></p>
<ul>
  <li>BSc program, or higher</li>
  <li>English: good, not necessarily proficient</li>
  <li>programming languages / other competences: Python, SciKit-learn</li>
</ul>

<p><strong>A maximum number of participants:</strong> 20</p>

<p><strong>What can the participant gain from the project?</strong></p>
<ul>
  <li>solving problems to data acquisition on a firmware level</li>
  <li>signal processing techniques</li>
  <li>practical approach to machine learning methodology</li>
</ul>

<p><strong>Is there a plan for extending this work to a peer-reviewed paper in case the results are promising?</strong> No.
However, the results, or methods proposed at the Brainhack project might be implemented in commercially offered device, Neuroon-Med.</p>

<hr />
<h2>Project 7: Building a brain-ageing biomarker using machine learning</h2>

<h4>Authors: James H Cole, PhD<sup>1</sup> <a href="mailto:james.cole@imperial.ac.uk"><i class="fa fa-envelope"></i></a> / Sebastian Popescu, MSc <sup>1</sup></h4>
<ol>
  <li>Computational, Cognitive &amp; Clinical Neuroimaging Laboratory (C3NL), Imperial College London</li>
</ol>

<p><strong>Abstract:</strong> As humans age, changes to the structure and function of the brain occur, so-called ‘brain ageing’. Brain ageing is associated with cognitive decline, decreased function capacity and a higher risk of neurodegenerative disease and dementia. A biomarker of the brain ageing process could have great utility in identifying people at risk of experiencing the adverse effects of brain ageing, before any symptoms manifest. Brain ageing biomarkers could also be useful for mapping individualised brain-ageing trajectories, assessing potential influences on brain ageing and in aiding the design of clinical trials.</p>

<p>Our work has used T1-MRI to design such a biomarker (brain-predicted age), taking voxelwise brain volume images and using a machine-learning regression to accurately predict chronological age in N=2001 healthy people aged 18-90. This follows the experimental design from biogerontology research that looks for measures of underlying ‘biological age’, and assesses the appropriateness of a measure based on the accuracy of age prediction. Our leading model has used voxelwise grey matter in a 3D convolutional neural network (CNN) approach, resulting in a mean absolute error (MAE) of 4.16 years, Pearson’s r = 0.96, R2 = 0.92. There is still considerable room for improvement in the model, to reduce the MAE towards minimal values. This is necessary if brain-predicted age is ever to have clinical impact, as currently the error levels mean that individualised predictions may be misleading.</p>

<p>The Hackathon project will encourage participants to develop their own brain-age prediction pipeline. Dataset #1 (N=2001) will be supplied, along with an independent validation set (dataset #2, N=650). These data will be in available in three formats: i) raw images, ii) FreeSurfer cortical thickness and subcortical volumes, iii) voxelwise grey matter and white matter volume images (derived from SPM). The participants can either use their own pre-processing pipeline or utilise the supplied processed datasets, then run any type of regression model of their choosing. This may or may not involve dimension reduction (e.g., PCA, clustering), feature selection (theory- or data-driven), use of kernels, regularisation and deep learning architectures.</p>

<p>The main dataset will be randomly partitioned into an 80-10-10% split, with separate samples for training, validation and testing. The final model will then also be assessed in dataset #2. The pipeline that results in the best test scores (i.e., MAE) for both dataset #1 and #2 will be declared the winner.
Finally, participants will be asked to consider ways of interpreting the feature importance, to help better understand the neuroanatomical features involved in the brain-age prediction.</p>

<p><img src="http://0.0.0.0:4000/img/projects/project7.jpg?style=centerme" alt="image-title-here" class="img-responsive" height="80%" width="80%" align="center" /></p>

<p><strong>A list of 1-5 key papers summarising the subject:</strong></p>
<ol>
  <li>Cole JH, Poudel RPK, Tsagkrasoulis D, et al. Predicting brain age with deep learning from raw imaging data results in a reliable and heritable biomarker. NeuroImage 2017. doi: 10.1016/j.neuroimage.2017.07.059</li>
  <li>Cole JH, Ritchie SJ, Bastin ME, et al. Brain age predicts mortality. Molecular psychiatry 2017. doi: 10.1038/mp.2017.62</li>
  <li>Franke K, Ziegler G, Klöppel S, Gaser C. Estimating the age of healthy subjects from T1-weighted MRI scans using kernel methods: Exploring the influence of various parameters. NeuroImage 2010; 50(3): 883-92.</li>
  <li>Konukoglu E, Glocker B, Zikic D, Criminisi A. Neighbourhood approximation using randomized forests. Medical Image Analysis 2013; 17(7): 790-804.</li>
  <li>Valizadeh SA, Hänggi J, Mérillat S, Jäncke L. Age prediction on the basis of brain anatomical measures. Human Brain Mapping 2017; 38(2): 997-1008.</li>
</ol>

<p><strong>A list of requirements for taking part in the project:</strong></p>
<ul>
  <li>conversational English</li>
  <li>Bachelor level of education</li>
  <li>basic understanding of statistical principles</li>
  <li>some experience of Machine Learning or other regression analysis in a language of their choice (e.g., python, Matlab, R or GUI-based software)</li>
</ul>

<p><strong>Maximum number of participants:</strong> 10</p>

<p><strong>What can the participant gain from the project?</strong>
Participants will gain an understanding of a key neuroscientific application of machine learning approaches, as well as an appreciation of the wider benefits of applying machine learning to biomedical problems. Particularly, participants will be encouraged to appreciate the importance of developing the whole analytic pipeline, rather than merely focusing on choice of machine learning algorithm. This includes considerations on pre-processing methods, feature selection and nested-cross-validation.</p>

<p><strong>Is there a plan for extending this work to a peer-reviewed paper in case the results are promising?</strong>
If a single prediction algorithm that generates a mean absolute error (MAE) less than the current leading application to these data (CNNs using voxelwise grey matter volume MAE = 4.16 years), then publication is warranted. The results of the different pipelines and algorithms used in the Hackathon will be then summarised and written up for submission to a peer-reviewed journal (e.g., NeuroImage, Human Brain Mapping, Frontiers in Aging Neuroscience), with all the Hackathon project participants included as co-authors, alongside the project team.</p>

<hr />

<h2>Project 8: Building and using the “FlyPi”: the 3D-printed Neurobiology Lab</h2>

<h4>Authors: Andre Maia Chagas / Eric James McDermott / Valerio Raco</h4>

<p><strong>Abstract:</strong></p>

<p>Small, genetically tractable species such as larval zebrafish, Drosophila, or Caenorhabditis elegans have become key model organisms in modern neuroscience. In addition to their low maintenance costs and easy sharing of strains across labs, one key appeal is the possibility to monitor single or groups of animals in a behavioural arena while controlling the activity of select neurons using optogenetic or thermogenetic tools. However, the purchase of a commercial solution for these types of experiments, including an appropriate camera system as well as a controlled behavioural arena, can be costly. Here, we present a low-cost and modular open-source alternative called the ‘FlyPi’.</p>

<p>Our design is based on a 3D-printed mainframe, a Raspberry Pi computer, and high-definition  camera  system as well as Arduino-based optical and thermal control circuits. Depending on the configuration, the FlyPi can be assembled for about €100 and features optional modules for light-emitting diode (LED)-based fluorescence microscopy and optogenetic stimulation as well as a Peltier-based temperature stimulator for thermogenetics. All functions of the FlyPi can be controlled through a custom-written graphical user interface. To demonstrate the FlyPi’s capabilities, we present its use in a series of state-of-the-art neurogenetics experiments. In addition, we demonstrate the FlyPi’s utility as a medical diagnostic tool as well as a teaching aid at Neurogenetics courses held at several African universities. Taken together, the low cost and modular nature as well as fully open design of the FlyPi make it a highly versatile tool in a range of applications, including the classroom, diagnostic centres, and research labs.</p>

<p><img src="http://0.0.0.0:4000/img/projects/project8.png?style=centerme" alt="image-title-here" class="img-responsive" height="80%" width="80%" align="center" /></p>

<p><strong>A list of 1-5 key papers / online materials summarising the subject:</strong></p>
<ol>
  <li>http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002086</li>
  <li>http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2002702</li>
  <li>https://hackaday.io/project/5059</li>
</ol>

<p><strong>A List of requirements for taking part in the project:</strong></p>
<ul>
  <li>Basic programming skills are advantageous but not mandatory</li>
  <li>basic English</li>
</ul>

<p><strong>Maximum number of participants:</strong>
20, working in pairs (participants do not need to apply in pairs, but this would be advantageous for building, maintaining and working with the FlyPi)</p>

<p><strong>What participants gain/learn from this  project:</strong>
In this project we want to teach participants how to build a DIY and affordable neurobiology lab. By having a hands on approach, participants will learn how to:</p>
<ul>
  <li>Solder electronic components</li>
  <li>Customise the user interface and program the device to do automated experiments</li>
  <li>Make affordable experiments using state-of-the-art neuroscience methods, such as optogenetics.</li>
  <li>Learn about open source hardware community and how to leverage OS technologies to make science more reliable, robust, and affordable.</li>
</ul>

<p><strong>Is there a plan for extending this work to a peer-reviewed paper in case the results are promising?</strong>
The project can be extended to a peer-reviewed paper when participants and project leaders think about educational literature.</p>

        </div>
      </div>
    
      
      <div id="schedule" class="section p-schedule">
        
        <div class="container ">
          <h1>Preliminary schedule</h1>

<table width="421" cellspacing="0" cellpadding="4" bgcolor="#cadfff">
<tbody>
<tr>
<td bgcolor="#ffffff" width="24" height="12">&nbsp;</td>
<td bgcolor="#ffffff" width="118">
<p lang="en-US"><span lang="en-US"><strong>Friday, 17th November 2017</strong></span></p>
</td>
<td bgcolor="#ffffff" width="127">
<p lang="en-US"><span lang="en-US"><strong>Saturday, 18th November 2017</strong></span></p>
</td>
<td bgcolor="#ffffff" width="119">
<p lang="en-US"><span lang="en-US"><strong>Sunday, 19th November 2017</strong></span></p>
</td>
</tr>


<tr>
<td bgcolor="#eeeeee" width="24" height="24">
<p lang="en-US">9:00</p>
</td>
<td bgcolor="#eeeeee" width="118">&nbsp;</td>
<td bgcolor="#81D4FA" width="127">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>
<td bgcolor="#81D4FA" width="119"><p lang="en-US"><span lang="en-US">brain hacking</span></p></td>
</tr>

<tr>
<td bgcolor="#ffffff" width="24" height="5">
<p lang="en-US">10:00</p>
</td>
<td bgcolor="#ffffff" width="118">&nbsp;</td>
<td bgcolor="#03A9F4" width="127">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>
<td bgcolor="#03A9F4" width="119">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>
</tr>

<tr>
<td bgcolor="#eeeeee" width="24" height="5">
<p lang="en-US">11:00</p>
</td>
<td bgcolor="#eeeeee" width="118">&nbsp;</td>
<td bgcolor="#81D4FA" width="127">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>
<td bgcolor="#81D4FA" width="119">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>
</tr>
<tr>
<td bgcolor="#ffffff" width="24" height="5">
<p lang="en-US">12:00</p>
</td>
<td bgcolor="#ffffff" width="118">&nbsp;</td>
<td bgcolor="#EF9A9A" width="127">
<p lang="en-US"><span lang="en-US">ignite talk: Michael Hanke</span></p>
<p lang="en-US"><span lang="en-US"><em><a href="index.html#hanke">Doing open science for your own benefit</a></em></span></p></td>
<td bgcolor="#03A9F4" width="119">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>

</tr>
<tr>
<td bgcolor="#eeeeee" width="24" height="5">
<p lang="en-US">13:00</p>
</td>
<td bgcolor="#eeeeee" width="118">&nbsp;</td>
<td bgcolor="#F4FF81" width="127">
<p lang="en-US"><span lang="en-US">lunch</span></p>
</td>
<td bgcolor="#F4FF81" width="119">
<p lang="en-US"><span lang="en-US">lunch</span></p>
</td>
</tr>
<tr>
<td bgcolor="#ffffff" width="24" height="5">
<p lang="en-US">14:00</p>
</td>
<td bgcolor="#ffffff" width="118">&nbsp;</td>
<td bgcolor="#03A9F4" width="127">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>
<td bgcolor="#16e6cf" width="119">
<p lang="en-US"><span lang="en-US">preparing final presentations</span></p>
</td>
</tr>
<tr>
<td bgcolor="#eeeeee" width="24" height="5">
<p lang="en-US">15:00</p>
</td>
<td bgcolor="#eeeeee" width="118">&nbsp;</td>
<td bgcolor="#81D4FA" width="127">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>
<td bgcolor="#72fce9" width="119">
<p lang="en-US"><span lang="en-US">a round of 10min final presentations</span></p>
</td>
</tr>
<tr>
<td bgcolor="#ffffff" width="24" height="5">
<p lang="en-US">16:00</p>
</td>
<td bgcolor="#ffffff" width="118">&nbsp;</td>
<td bgcolor="#03A9F4" width="127">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>
<td bgcolor="#16e6cf" width="119">
<p lang="en-US"><span lang="en-US">a round of 10min final presentations</span></p>
</td>
</tr>
<tr>
<td bgcolor="#eeeeee" width="24" height="38">
<p lang="en-US">17:00</p>
</td>
<td bgcolor="#F4FF81" width="118">
<p lang="en-US"><span lang="en-US">opening, welcome drinks</span></p>
</td>
<td bgcolor="#EF9A9A" width="127">
<p lang="en-US"><span lang="en-US">tea-time talk: Charl Linssen</span></p>
<p><span lang="en-US"><em><a href="index.html#charl">Convergence between artificial intelligence and simulation of the brain: from theory to github</a></em></span></p>
</td>
<td bgcolor="#EF9A9A" width="119">
<p lang="en-US"><span lang="en-US">closing talk: Kirstie Whitaker</span></p>
<p><span lang="en-US"><em><a href="index.html#kirstie">Shooting for the stars: Moving from reproducible to open research (skype talk)</a></em></span></p>
</td>
</tr>
<tr>
<td bgcolor="#ffffff" width="24" height="13">
<p lang="en-US">18:00</p>
</td>
<td bgcolor="#16e6cf" width="118">
<p lang="en-US"><span lang="en-US">presentations by partnering institutions</span></p>
</td>
<td bgcolor="#03A9F4" width="127">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>
<td bgcolor="#F4FF81" width="119">
<p lang="en-US"><span lang="en-US">goodbye drinks</span></p>
</td>
</tr>
<tr>
<td bgcolor="#eeeeee" width="24" height="38">
<p lang="en-US">19:00</p>
</td>
<td bgcolor="#72fce9" width="118">
<p lang="en-US"><span lang="en-US">5min blitz project opening presentations</span></p>
</td>
<td bgcolor="#81D4FA" width="127">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>
<td bgcolor="#eeeeee" width="119">&nbsp;</td>

</tr>
<tr>
<td bgcolor="#ffffff" width="24" height="13">
<p lang="en-US">20:00</p>
</td>
<td bgcolor="#B39DDB" width="118">
<p lang="en-US"><span lang="en-US">a small excursion together to Warsaw downtown</span></p>
</td>
<td bgcolor="#F4FF81" width="127">
<p lang="en-US"><span lang="en-US">dinner</span></p>
</td>
<td bgcolor="#ffffff" width="119">&nbsp;</td>

</tr>
<tr>
<td bgcolor="#eeeeee" width="24" height="5">
<p lang="en-US">21:00</p>
</td>
<td bgcolor="#eeeeee" width="118">&nbsp;</td>
<td bgcolor="#81D4FA" width="127">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>
<td bgcolor="#eeeeee" width="119">&nbsp;</td>
</tr>
<tr>
<td bgcolor="#ffffff" width="24" height="5">
<p lang="en-US">22:00</p>
</td>
<td bgcolor="#ffffff" width="118">&nbsp;</td>
<td bgcolor="#03A9F4" width="127">
<p lang="en-US"><span lang="en-US">brain hacking</span></p>
</td>
<td bgcolor="#ffffff" width="119">&nbsp;</td>
</tr>
<tr>
<td bgcolor="#eeeeee" width="24" height="4">
<p lang="en-US">23:00</p>
</td>
<td bgcolor="#eeeeee" width="118">&nbsp;</td>
<td bgcolor="#B39DDB" width="127">
<p lang="en-US"><span lang="en-US">late-night social (details t.b.a.)</span></p>
</td>
<td bgcolor="#eeeeee" width="119">&nbsp;</td>
</tr>

</tbody>
</table>

        </div>
      </div>
    
      
      <div id="register" class="section p-register">
        
        <div class="container ">
          <h1>Registration</h1>

<p>Please send the project proposals before 1st September  2017 to the mailing address: <a href="mailto:brainhackwarsaw@gmail.com">brainhackwarsaw@gmail.com</a></p>

<p>Registration for project participants will start in September and it will last until 1st November 2017 .</p>

<p>During registration, there will be small  registration fee for the project participants (to cover the catering during the event, not more than 20€)</p>


        </div>
      </div>
    
      
      <div id="comitee" class="section p-comitee">
        
        <div class="container ">
          <h1>Commitee</h1>

<h2>The AoN Brainhack Warsaw 2017 committee:</h2>

<div id="profile-container">
<aside class="profile-card ">
   <header>
   <img src="http://0.0.0.0:4000/img/comitee/nat.jpg" />
    <h5>Natalia Bielczyk, Msc 
<a href="https://www.nataliabielczyk.com"><i class="fa fa-home fa-vc" style="position: relative; top: -3px; text-indent:0px; "></i></a>
 <a href="https://twitter.com/nataliabielczyk"><i class="fa fa-twitter" style="position: relative; top: -5px;text-indent:0px;  vertical-align: middle;"></i></a> 

 <a href="https://www.researchgate.net/profile/Natalia_Bielczyk2"> <i class="ai ai-researchgate fa-vc" style="  margin-bottom: -50px;position: relative; top: -5px;text-indent:0px;"></i></a> </h5>
    <h6>Statistical Imaging Neuroscience Research Group, Donders Institute for Brain, Cognition and Behavior, <br />Nijmegen, The Netherlands</h6>
   </header>
</aside>



<aside class="profile-card ">
   <header>
   <img src="http://0.0.0.0:4000/img/comitee/bielski.JPG" />
    <h5>Krzysztof Bielski

 <a href="https://twitter.com/KrzysztofBiels1"><i class="fa fa-twitter" style="position: relative; top: -5px;text-indent:0px;  vertical-align: middle;"></i></a> 

 </h5>
    <h6>Faculty of Psychology, University of Warsaw,<br /> Warsaw, Poland</h6>
   </header>
</aside>


	

<aside class="profile-card ">
   <header>
   <img src="http://0.0.0.0:4000/img/comitee/borek.jpg" />
    <h5>Daniel Borek

 <a href="https://twitter.com/danieltomasz"><i class="fa fa-twitter" style="position: relative; top: -5px;text-indent:0px;  vertical-align: middle;"></i></a> 
 <a href="https://github.com/danieltomasz"><i class="fa fa-github" style="position: relative; top: -5px; text-indent:0px;  "></i></a>
 </h5>
    <h6>College of Inter-Faculty Individual Studies in Mathematics and Natural Sciences (MISMaP),<br /> Faculty of Physics, University of Warsaw, <br />Warsaw, Poland</h6>
   </header>
</aside>




</div>

<h2>Advisory board:</h2>
<div id="profile-container">

<aside class="advisory-card ">
   <header>
   <img src="http://0.0.0.0:4000/img/comitee/michal.png" />
    <h5>Michał Bola, PhD 



 </h5>
    <h6>Laboratory of Brain Imaging,<br /> Nencki Institute of Experimental Biology PAS,<br /> Warsaw, Poland</h6>
   </header>
</aside>





<aside class="advisory-card ">
   <header>
   <img src="http://0.0.0.0:4000/img/comitee/Daniel_Wojcik.png" />
    <h5>Prof. Daniel Wójcik 



 </h5>
    <h6>Laboratory of Neuroinformatics,<br /> Department of Neurophysiology, <br />
Nencki Institute of Experimental Biology PAS,<br /> Warsaw, Poland</h6>
   </header>
</aside>





<aside class="advisory-card ">
   <header>
   <img src="http://0.0.0.0:4000/img/comitee/jaroslaw.jpg" />
    <h5>Jarosław Żygierewicz, PhD



 </h5>
    <h6>Neuroinformatics, <br /> Biomedical Physics Division,<br /> Faculty of Physics, University of Warsaw,<br /> Warsaw, Poland</h6>
   </header>
</aside>



</div>

        </div>
      </div>
    
 
    <div id="footer" class="section text-white">
      <div class="container">
        
        <p><i class="fa fa-angle-left"></i><i class="fa fa-angle-right"></i>  by <a href="#borek">Daniel Borek</a> on <a href="https://github.com/t413/SinglePaged">SinglePaged theme</a></p>


      </div>
    </div>
  </div>



  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
  <script src="site.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.97.1/js/materialize.min.js"></script>
  <script type="text/javascript" src="//cdn.jsdelivr.net/jquery.slick/1.5.7/slick.min.js"></script>

</body>
</html>
